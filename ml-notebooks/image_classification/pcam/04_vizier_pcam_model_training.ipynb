{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AksIKBzZ-nre"
   },
   "source": [
    "# Using Vertex AI Vizier for ML model hyperparameter tuning\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This example demonstrates the use of [Vertex AI Vizier](https://cloud.google.com/vertex-ai/docs/vizier/overview) for [hyperparameter (HP) tuning](https://en.wikipedia.org/wiki/Hyperparameter_optimization) of an ML model. Vertex AI Vizier is a black-box optimization service. You will often see Vertex AI Vizier used to optimize hyperparameters of ML models, but it can also perform other optimization tasks.\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/amy-jo/images/vertex/vizier/vizier1.png\" width=\"65%\">\n",
    "\n",
    "**For more information about the model and dataset used in this example, see [the `01_keras_pcam` notebook](app.terra.bio/#workspaces/verily-terra-solutions/ml-on-terra/notebooks/launch/01_keras_pcam.ipynb)**. As with that notebook, we'll train a model using the workspace's Cloud Environment, but this time we'll use Vizier for HP tuning.\n",
    "\n",
    "For this notebook, use the default Terra Cloud Environment image, **customized to use at least 1 GPU and at least 4 cores**.\n",
    "\n",
    "> **Note**: The [02_2_vertex_ai_pcam.ipynb](https://app.terra.bio/#workspaces/verily-terra-solutions/ml-on-terra/notebooks/launch/02_2_vertex_ai_pcam.ipynb) notebook also includes an HP tuning example. That example uses a service that is integrated with Vertex AI training. The Vizier service— that we show here— is a standalone optimization service, so it can be used for any optimization task that you like, and is thus more flexible.\n",
    "Under the hood, both use the same underlying technology.\n",
    "\n",
    "\n",
    "### 'Native' GCP project required\n",
    "\n",
    "This example requires a ['native' GCP project](https://support.terra.bio/hc/en-us/articles/360051229072-Accessing-advanced-GCP-features-in-Terra).  The Vizier service will be run using that project, not your Terra workspace project.\n",
    "\n",
    "### Hyperparameters and optimization objective\n",
    "\n",
    "In this simple example, we'll use batch size and learning rate as the hyperparameters, and optimize for accuracy.\n",
    "\n",
    "### Overview of running a Vizier *study*\n",
    "\n",
    "Here is an overview of the process for setting up and running a Vizier study. The specifics are in the code below.\n",
    "\n",
    "- Create a *study* configuration. This includes info on the parameter(s) that you want to tune,your objective metric(s), and the HP search algorithm to use.\n",
    "- Create a Vizier client object via the `aiplatform` libs, which you'll use to interact with the service.\n",
    "- Create a Vizier *study* via the client object\n",
    "- Define function(s) to evaluate the objective metric(s).\n",
    "- Run the trials by interacting with the Vizier client to get \"suggested\" trial param sets. Run your evaluation functions using the suggested trial param sets.\n",
    "- Record the outcome of a given trial with the Vizier client. You use a `client_id` to indicate the identifier of the client that is requesting the suggestion. If multiple suggestion requests have the same `client_id`, the service will return the identical suggested trial if the trial is PENDING, and provide a new trial if the last suggested trial was completed.\n",
    "- Request information from Vizier about the optimal trials. It returns the pareto-optimal trials for a multi-objective study, or the optimal trials for a single-objective study.\n",
    "\n",
    "### Costs\n",
    "\n",
    "This tutorial uses Vertex AI Vizier. Pricing information is [here](https://cloud.google.com/vertex-ai/pricing#vizier).\n",
    "For this simple example, which uses `RANDOM_SEARCH`, there should not be a charge to your 'native' GCP project, so you should just incur the costs of running this notebook. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMHz63rPbq6P"
   },
   "source": [
    "## Setup\n",
    "\n",
    "### Install the Vertex AI library\n",
    "\n",
    "Download and install the Vertex AI library. You only need to run this once for a given persistent disk. (On the default Terra image, this library should already be installed, though this command will update it if need be)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g7WlujNxbq6Q"
   },
   "outputs": [],
   "source": [
    "! unset PIP_TARGET ; pip install --user --upgrade google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O8AIwN0abq6U"
   },
   "outputs": [],
   "source": [
    "# Restart the kernel after pip installs\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xc9LnICki2Xp"
   },
   "source": [
    "### Set up your 'native' Google Cloud project\n",
    "\n",
    "1. If you have not already done so, follow the instructions [here](https://support.terra.bio/hc/en-us/articles/360051229072-Accessing-advanced-GCP-features-in-Terra) for a GCP project, including creating a Terra group as necessary, and then adding your Terra group on the Google project. You'll need to enable billing as described in the article.\n",
    "\n",
    "2. Then, [enable the Vertex AI APIs](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com) for your project.\n",
    "\n",
    "You'll need to fill in the project ID for your native project in the next cell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dax2zrpTi2Xy"
   },
   "source": [
    "### Import libraries and define constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before you run the following cell**, set the `PROJECT_ID` for your ['native' GCP project](https://support.terra.bio/hc/en-us/articles/360051229072-Accessing-advanced-GCP-features-in-Terra)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"\n",
    "# Set your 'native' GCP project ID here, NOT your workspace project ID\n",
    "PROJECT_ID = \"YOUR-NATIVE-PROJECT-ID\"  # CHANGE THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xD60d6Q0i2X0"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (\n",
    "    \"GOOGLE_PROJECT\" in os.environ\n",
    "):  # This env var is set when running in a Terra workspace\n",
    "\n",
    "    WORKSPACE_NAME = os.environ[\"WORKSPACE_NAME\"]\n",
    "    WORKSPACE_NAMESPACE = os.environ[\"WORKSPACE_NAMESPACE\"]\n",
    "    WORKSPACE_BUCKET = os.environ[\"WORKSPACE_BUCKET\"]\n",
    "else:\n",
    "    print(\"Not running on Terra: you will need to set your GCP bucket manually.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = WORKSPACE_BUCKET\n",
    "print(BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the tissue datasets\n",
    "\n",
    "This process will take a while. We'll download to the persistent disk, so that you only need to do the download once (per PD).  So, if you have already run the [01_keras_pcam](app.terra.bio/#workspaces/verily-terra-solutions/ml-on-terra/notebooks/launch/01_keras_pcam.ipynb) on the same PD, the `load` method should run very quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the input data from tensorflow_datasets\n",
    "ds, ds_info = tfds.load(\n",
    "    \"patch_camelyon\",\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    "    data_dir=\"/home/jupyter/tensorflow_datasets\",\n",
    ")\n",
    "\n",
    "# get the train, validation and test datasets\n",
    "train_data = ds[\"train\"]\n",
    "valid_data = ds[\"validation\"]\n",
    "test_data = ds[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the train_data\n",
    "buffer_size = 1000\n",
    "train_data = train_data.shuffle(buffer_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view a few of the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_datat = train_data.batch(batch_size).prefetch(1)\n",
    "\n",
    "for images, labels in train_datat.take(3):\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    first_image = images[0]\n",
    "    plt.imshow(first_image.numpy().astype(\"int32\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Keras image classification model\n",
    "\n",
    "In this section, we'll define the Keras model that we'll use for training. We'll use [transfer learning](https://en.wikipedia.org/wiki/Transfer_learning) for this example, starting with a model— the [Xception](https://keras.io/api/applications/xception/) convolutional neural network architecture — that has been trained on [ImageNet](https://www.image-net.org/) data, and adding some additional layers to that model. We'll 'freeze' the Xception base model, so that its weights don't change during training; only the weights of our new layers will change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model(learning_rate):\n",
    "    base_model = keras.applications.Xception(\n",
    "        weights=\"imagenet\", input_shape=(96, 96, 3), include_top=False\n",
    "    )\n",
    "\n",
    "    base_model.trainable = False\n",
    "\n",
    "    inputs = keras.Input(shape=(96, 96, 3))\n",
    "\n",
    "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "    x = base_model(x, training=False)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "    outputs = keras.layers.Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=loss,\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return (base_model, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_training(\n",
    "    batch_size, learning_rate, tdata, vdata, tstdata, log_dir, epochs\n",
    "):\n",
    "\n",
    "    # batch and prefetch\n",
    "    train_data = tdata.batch(batch_size).prefetch(1)\n",
    "    valid_data = vdata.batch(batch_size).prefetch(1)\n",
    "    test_data = tstdata.batch(batch_size).prefetch(1)\n",
    "\n",
    "    ts = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    print(ts)\n",
    "\n",
    "    model = get_compiled_model(learning_rate)\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))\n",
    "    if strategy.num_replicas_in_sync > 1:\n",
    "        print(\"Using mirrored strategy.\")\n",
    "        with strategy.scope():\n",
    "            base_model, model = get_compiled_model(learning_rate)\n",
    "    else:\n",
    "        base_model, model = get_compiled_model(learning_rate)\n",
    "    model.summary()\n",
    "\n",
    "    # Define some training 'callbacks'. One logs in a format used by https://www.tensorflow.org/tensorboard.\n",
    "    # The other sets up model checkpointing.\n",
    "    # If training is interrupted for some reason, we can reconstitute the last-saved model from the\n",
    "    # checkpoint directory.\n",
    "    print(log_dir)\n",
    "    checkpoint_dir = f\"./checkpoints/{ts}/checkpoints\"\n",
    "    print(checkpoint_dir)\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=log_dir, update_freq=300\n",
    "    )\n",
    "\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_dir, monitor=\"val_accuracy\", mode=\"max\", save_freq=\"epoch\"\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        train_data,\n",
    "        epochs=epochs,\n",
    "        callbacks=[tensorboard_callback, model_checkpoint_callback],\n",
    "        validation_data=valid_data,\n",
    "    )\n",
    "\n",
    "    # get some metrics info\n",
    "    print(f\"model history: {model.history.history}\")\n",
    "    val_accuracy = (model.history.history[\"val_accuracy\"])[-1]\n",
    "    val_loss = (model.history.history[\"val_loss\"])[-1]\n",
    "    print(f\"val_loss: {val_loss}; val_accuracy: {val_accuracy}\")\n",
    "    #   eval_res = model.evaluate(test_data)\n",
    "    #   print(f\"eval res: {eval_res}\")\n",
    "    return (model, val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CWuu4wmki2X3"
   },
   "source": [
    "## Define and run a Vizier *study*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyEjqIdnad0w"
   },
   "source": [
    "Set some variables.  Ensure that your `PROJECT_ID` is set correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8HCgeF8had77"
   },
   "outputs": [],
   "source": [
    "STUDY_DISPLAY_NAME = \"{}_study_{}\".format(\n",
    "    PROJECT_ID.replace(\"-\", \"\"), datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    ")  # @param {type: 'string'}\n",
    "ENDPOINT = REGION + \"-aiplatform.googleapis.com\"\n",
    "PARENT = \"projects/{}/locations/{}\".format(PROJECT_ID, REGION)\n",
    "\n",
    "print(\"ENDPOINT: {}\".format(ENDPOINT))\n",
    "print(\"REGION: {}\".format(REGION))\n",
    "print(\"PARENT: {}\".format(PARENT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8NBduXsEaRKr"
   },
   "source": [
    "### Create the *study* configuration\n",
    "\n",
    "The study configuration is built as a hierarchical python dictionary. It is already filled out. Run the cell to configure the study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "id": "s-AHfPOASXXW"
   },
   "outputs": [],
   "source": [
    "# Parameter Configuration\n",
    "\n",
    "param_batch_size = {\n",
    "    \"parameter_id\": \"batch_size\",\n",
    "    \"discrete_value_spec\": {\"values\": [16, 32, 64, 128, 256], \"default_value\": 32},\n",
    "}\n",
    "\n",
    "param_learning_rate = {\n",
    "    \"parameter_id\": \"learning_rate\",\n",
    "    \"discrete_value_spec\": {\"values\": [1e-4, 1e-3, 1e-2, 1e-1], \"default_value\": 1e-3},\n",
    "}\n",
    "\n",
    "# Objective Metrics\n",
    "metric_acc = {\"metric_id\": \"accuracy\", \"goal\": \"MAXIMIZE\"}\n",
    "\n",
    "\n",
    "# Put it all together in a study configuration\n",
    "study = {\n",
    "    \"display_name\": STUDY_DISPLAY_NAME,\n",
    "    \"study_spec\": {\n",
    "        \"algorithm\": \"RANDOM_SEARCH\",\n",
    "        \"parameters\": [\n",
    "            param_batch_size,\n",
    "            param_learning_rate,\n",
    "        ],\n",
    "        \"metrics\": [metric_acc],\n",
    "    },\n",
    "}\n",
    "\n",
    "print(json.dumps(study, indent=2, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uyXG_RKha7Kb"
   },
   "source": [
    "### Create the Vizier *study*\n",
    "\n",
    "Next, create the study, which you will run to optimize the objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jgskzqZX0Mkt"
   },
   "outputs": [],
   "source": [
    "vizier_client = aiplatform.gapic.VizierServiceClient(\n",
    "    client_options=dict(api_endpoint=ENDPOINT)\n",
    ")\n",
    "study = vizier_client.create_study(parent=PARENT, study=study)\n",
    "STUDY_ID = study.name\n",
    "print(\"STUDY_ID: {}\".format(STUDY_ID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKOMBKmtkcJb"
   },
   "source": [
    "### Metric evaluation functions\n",
    "\n",
    "Next, define a function to evaluate the objective metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xnl1uqnyz3Qp"
   },
   "outputs": [],
   "source": [
    "def CreateMetrics(trial_id, batch_size, learning_rate, epochs, study_disp_name):\n",
    "    print((\"=========== Start Trial: [{}] =============\").format(trial_id))\n",
    "    print(f\"using batch_size {batch_size}; learning_rate {learning_rate}\")\n",
    "\n",
    "    # Evaluate objective metrics for this trial\n",
    "    LOG_DIR = f\"{BUCKET}/logs/pcam/{study_disp_name}/{trial_id.split('/')[-1]}\"\n",
    "    print(LOG_DIR)\n",
    "\n",
    "    m, accuracy = run_model_training(\n",
    "        batch_size, learning_rate, train_data, valid_data, test_data, LOG_DIR, epochs\n",
    "    )\n",
    "    print(f\"accuracy: {accuracy}\")\n",
    "\n",
    "    acc = {\"metric_id\": \"accuracy\", \"value\": accuracy}\n",
    "\n",
    "    # Return the results for this trial\n",
    "    return [acc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qzn5lVpRq05U"
   },
   "source": [
    "### Set configuration parameters for running trials\n",
    "\n",
    "__`client_id`__: The identifier of the client that is requesting the suggestion. If multiple suggestion requests have the same `client_id`, the service will return the identical suggested trial if the trial is `PENDING`, and provide a new trial if the last suggested trial was completed.\n",
    "\n",
    "__`suggestion_count_per_request`__: The number of suggestions (trials) requested in a single request.\n",
    "\n",
    "__`max_trial_id_to_stop`__: The number of trials to explore before stopping. It is set to 15 to shorten the time to run the code, so don't expect convergence. For convergence, it would likely need to be about 20 (a good rule of thumb is to multiply the total dimensionality by 10).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5usXaZA5qvUZ"
   },
   "outputs": [],
   "source": [
    "client_id = \"client_pcam\"\n",
    "suggestion_count_per_request = 1\n",
    "# For example purposes, we'll only run two trials.  In a 'real' study you'd want more.\n",
    "# Feel free to edit this variable if you like.\n",
    "max_trial_id_to_stop = 2\n",
    "\n",
    "print(\"client_id: {}\".format(client_id))\n",
    "print(\"suggestion_count_per_request: {}\".format(suggestion_count_per_request))\n",
    "print(\"max_trial_id_to_stop: {}\".format(max_trial_id_to_stop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UnV2SJNskm7V"
   },
   "source": [
    "### Run Vertex Vizier trials\n",
    "\n",
    "Run the trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "opmuTntW4-eS"
   },
   "outputs": [],
   "source": [
    "trial_id = 0\n",
    "EPOCHS = 2\n",
    "\n",
    "while int(trial_id) < max_trial_id_to_stop:\n",
    "    suggest_response = vizier_client.suggest_trials(\n",
    "        {\n",
    "            \"parent\": STUDY_ID,\n",
    "            \"suggestion_count\": suggestion_count_per_request,\n",
    "            \"client_id\": client_id,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    for suggested_trial in suggest_response.result().trials:\n",
    "        trial_id = suggested_trial.name.split(\"/\")[-1]\n",
    "        trial = vizier_client.get_trial({\"name\": suggested_trial.name})\n",
    "\n",
    "        if trial.state in [\"COMPLETED\", \"INFEASIBLE\"]:\n",
    "            continue\n",
    "\n",
    "        for param in trial.parameters:\n",
    "            if param.parameter_id == \"batch_size\":\n",
    "                batch_size = param.value\n",
    "            elif param.parameter_id == \"learning_rate\":\n",
    "                learning_rate = param.value\n",
    "        print(\n",
    "            \"Trial : batch_size is {}, learning_rate is {}.\".format(\n",
    "                batch_size, learning_rate\n",
    "            )\n",
    "        )\n",
    "\n",
    "        vizier_client.add_trial_measurement(\n",
    "            {\n",
    "                \"trial_name\": suggested_trial.name,\n",
    "                \"measurement\": {\n",
    "                    \"metrics\": CreateMetrics(\n",
    "                        suggested_trial.name,\n",
    "                        int(batch_size),\n",
    "                        learning_rate,\n",
    "                        EPOCHS,\n",
    "                        STUDY_DISPLAY_NAME,\n",
    "                    )\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "\n",
    "        response = vizier_client.complete_trial(\n",
    "            {\"name\": suggested_trial.name, \"trial_infeasible\": False}\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5ZTqgqBiRsq"
   },
   "source": [
    "### List the optimal solutions\n",
    "\n",
    "`list_optimal_trials` returns the [pareto-optimal](https://en.wikipedia.org/wiki/Pareto_efficiency) trials for a multi-objective study, or the optimal trials for single-objective study. For this example, we defined a single-objective study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Or2PL1YxTr33"
   },
   "outputs": [],
   "source": [
    "optimal_trials = vizier_client.list_optimal_trials({\"parent\": STUDY_ID})\n",
    "\n",
    "print(\"optimal_trials: {}\".format(optimal_trials))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View your trial results in the Vertex AI UI\n",
    "\n",
    "To view and compare your trial results, you can visit the [Vertex AI \"Experiments\" panel](https://console.cloud.google.com/vertex-ai/experiments/experiments) in the GCP Cloud Console, then click on the **VIZIER STUDIES** tab. From there, click in to a \"Study name\".\n",
    "\n",
    "You can view info about the trial metrics as they are run.  For example, here is an study using the example from this notebook, after 6 trials:\n",
    "<img src=\"https://storage.googleapis.com/amy-jo/images/vertex/vizier/vizier2.png\">\n",
    "\n",
    "...and after 15 trials, sorted by the target metric, `accuracy`:\n",
    "<img src=\"https://storage.googleapis.com/amy-jo/images/vertex/vizier/vizier1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KAxfq9Fri2YV"
   },
   "source": [
    "## Listing, fetching, and deleting studies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To list studies in a specific project and region, send the following request:\n",
    "vizier_client.list_studies({\"parent\": PARENT})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get a study config, send the following request\n",
    "# The STUDY_ID string has the format 'projects/<your_project_number>/locations/us-central1/studies/<study_id>'\n",
    "vizier_client.get_study({\"name\": STUDY_ID})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zQlLDfvlzYde"
   },
   "outputs": [],
   "source": [
    "# To delete a study:\n",
    "vizier_client.delete_study({\"name\": STUDY_ID})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fPc-KWUi2Xd"
   },
   "source": [
    "---\n",
    "Copyright 2022 Verily Life Sciences LLC\n",
    "\n",
    "Use of this source code is governed by a BSD-style    \n",
    "license that can be found in the LICENSE file or at    \n",
    "https://developers.google.com/open-source/licenses/bsd"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "gapic-vizier-multi-objective-optimization.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
